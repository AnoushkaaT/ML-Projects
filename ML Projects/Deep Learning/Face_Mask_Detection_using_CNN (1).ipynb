{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"N_CLqBul-P73","executionInfo":{"status":"ok","timestamp":1708706338818,"user_tz":-330,"elapsed":5833,"user":{"displayName":"Baseer Siddiqui","userId":"01484664065372194745"}},"outputId":"64e0f2c4-3388-46e1-840a-9942357ac6fe","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (1.5.16)\n","Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.16.0)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from kaggle) (2024.2.2)\n","Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.8.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.31.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle) (4.66.2)\n","Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle) (8.0.4)\n","Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.0.7)\n","Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle) (6.1.0)\n","Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle) (0.5.1)\n","Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle) (1.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.6)\n"]}],"source":["!pip install kaggle"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"O_r4NfUt-nQn"},"outputs":[],"source":["# configuring the path of Kaggle.json file\n","!mkdir -p ~/.kaggle\n","!cp kaggle.json ~/.kaggle/\n","!chmod 600 ~/.kaggle/kaggle.json"]},{"cell_type":"markdown","metadata":{"id":"1WQ0q_5mOiqj"},"source":["[link text](https://)Importing Face Mask Dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GRuZtxBmOf1Y","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1708706339572,"user_tz":-330,"elapsed":14,"user":{"displayName":"Baseer Siddiqui","userId":"01484664065372194745"}},"outputId":"93aff72f-e44b-4e1a-f7ab-fa18e5a3e68d"},"outputs":[{"output_type":"stream","name":"stdout","text":["401 - Unauthorized - Unauthenticated\n"]}],"source":["# API to fetch the dataset from Kaggle\n","!kaggle datasets download -d omkargurav/face-mask-dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"STZzd8ghOuE0","colab":{"base_uri":"https://localhost:8080/","height":349},"executionInfo":{"status":"error","timestamp":1708706339572,"user_tz":-330,"elapsed":11,"user":{"displayName":"Baseer Siddiqui","userId":"01484664065372194745"}},"outputId":"1ed506dc-1f18-4e1e-beda-7e226eaf4a0d"},"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: '/content/face-mask-dataset.zip'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-5-d5f30a73bcaa>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/face-mask-dataset.zip'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m   \u001b[0mzip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextractall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'The dataset is extracted'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/zipfile.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, file, mode, compression, allowZip64, compresslevel, strict_timestamps)\u001b[0m\n\u001b[1;32m   1249\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1250\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1251\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilemode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1252\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1253\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mfilemode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodeDict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/face-mask-dataset.zip'"]}],"source":["# extracting the compessed Dataset\n","from zipfile import ZipFile\n","dataset = '/content/face-mask-dataset.zip'\n","\n","with ZipFile(dataset,'r') as zip:\n","  zip.extractall()\n","  print('The dataset is extracted')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hMWRxwcpO5n8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1708706401091,"user_tz":-330,"elapsed":813,"user":{"displayName":"Baseer Siddiqui","userId":"01484664065372194745"}},"outputId":"5dc6ac8c-13bf-4709-dbb1-22e166fdb240"},"outputs":[{"output_type":"stream","name":"stdout","text":[" kaggle.json\t\t\t\t\t    'WhatsApp Image 2024-02-23 at 2.28.10 PM.jpeg'\n"," sample_data\t\t\t\t\t    'WhatsApp Video 2024-02-22 at 8.19.24 PM.mp4'\n","'WhatsApp Image 2024-02-23 at 2.28.10 PM (1).jpeg'\n"]}],"source":["!ls"]},{"cell_type":"markdown","metadata":{"id":"MKIrkEC5zrjA"},"source":["**Importing the Dependencies**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yEUQCcZPzlfo"},"outputs":[],"source":["import os\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import matplotlib.image as mpimg\n","import cv2\n","from google.colab.patches import cv2_imshow\n","from PIL import Image\n","from sklearn.model_selection import train_test_split"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"i4xGbBHq0PSo","colab":{"base_uri":"https://localhost:8080/","height":176},"executionInfo":{"status":"error","timestamp":1708706497557,"user_tz":-330,"elapsed":660,"user":{"displayName":"Baseer Siddiqui","userId":"01484664065372194745"}},"outputId":"616d4263-ef26-43cb-8f2c-c0a72e8e0241"},"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: '/content/data/with_mask'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-12-4acece5a6f04>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mwith_mask_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/data/with_mask'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwith_mask_files\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwith_mask_files\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/data/with_mask'"]}],"source":["with_mask_files = os.listdir('/content/data/with_mask')\n","print(with_mask_files[0:5])\n","print(with_mask_files[-5:])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"K_q6sypb0mqK","colab":{"base_uri":"https://localhost:8080/","height":176},"executionInfo":{"status":"error","timestamp":1708706444941,"user_tz":-330,"elapsed":669,"user":{"displayName":"Baseer Siddiqui","userId":"01484664065372194745"}},"outputId":"c1f5b0db-3f5e-4d12-bfe2-6610720a26ef"},"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: '/content/data/without_mask'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-11-024d54fcc3ea>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mwithout_mask_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/data/without_mask'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwithout_mask_files\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwithout_mask_files\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/data/without_mask'"]}],"source":["without_mask_files = os.listdir('/content/data/without_mask')\n","print(without_mask_files[0:5])\n","print(without_mask_files[-5:])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"o5s8Mk350yqo"},"outputs":[],"source":["print('Number of with mask images:', len(with_mask_files))\n","print('Number of without mask images:', len(without_mask_files))"]},{"cell_type":"markdown","metadata":{"id":"fIEifMkE1Vr8"},"source":["**Creating Labels for the two class of Images**"]},{"cell_type":"markdown","metadata":{"id":"VDqdbJ4I1c9z"},"source":["with mask  -->  1\n","\n","without mask  -->  0"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"M2EK-RtI1FUS"},"outputs":[],"source":["# create the labels\n","\n","with_mask_labels = [1]*3725\n","\n","without_mask_labels = [0]*3828"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xJTydgcb13Bc"},"outputs":[],"source":["print(with_mask_labels[0:5])\n","\n","print(without_mask_labels[0:5])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OrIbqLhV193_"},"outputs":[],"source":["print(len(with_mask_labels))\n","print(len(without_mask_labels))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"i7H-OSqA2HZ-"},"outputs":[],"source":["labels = with_mask_labels + without_mask_labels\n","\n","print(len(labels))\n","print(labels[0:5])\n","print(labels[-5:])"]},{"cell_type":"markdown","metadata":{"id":"4OZz81JJ2d_r"},"source":["**Displaying the Images**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QI7jBEJ02VQ9"},"outputs":[],"source":["# displaying with mask image\n","img = mpimg.imread('/content/data/with_mask/with_mask_1545.jpg')\n","imgplot = plt.imshow(img)\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wwbhVmkr28rh"},"outputs":[],"source":["# displaying without mask image\n","img = mpimg.imread('/content/data/without_mask/without_mask_2925.jpg')\n","imgplot = plt.imshow(img)\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"r6Q8CJBH3V21"},"source":["**Image Processing**"]},{"cell_type":"markdown","metadata":{"id":"faTbplf63ZXB"},"source":["1. Resize the Images\n","\n","2. Convert the images to numpy arrays"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GjR7Vmg73MMj"},"outputs":[],"source":["# convert images to numpy arrays\n","\n","with_mask_path = '/content/data/with_mask/'\n","\n","data = []\n","\n","# Iterate over all image files in the with_mask directory\n","for img_file in with_mask_files:\n","  # Open the image file\n","  image = Image.open(with_mask_path + img_file)\n","  # Resize the image to 128x128\n","  image = image.resize((128,128))\n","  # Convert the image to RGB format\n","  image = image.convert('RGB')\n","  # Convert the image to a NumPy array\n","  image = np.array(image)\n","  # Append the NumPy array to the data list\n","  data.append(image)\n","\n","\n","without_mask_path = '/content/data/without_mask/'\n","\n","\n","for img_file in without_mask_files:\n","# Iterate over all image files in the without_mask directory\n","  image = Image.open(without_mask_path + img_file)\n","  image = image.resize((128,128))\n","  image = image.convert('RGB')\n","  image = np.array(image)\n","  data.append(image)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kL1ETkSK6Sxu"},"outputs":[],"source":["type(data)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dpgz_u2-6eQo"},"outputs":[],"source":["len(data)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4uD6dF1v6fsg"},"outputs":[],"source":["data[0]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HIyzW_yZ6k6m"},"outputs":[],"source":["type(data[0])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iXoDEYCe6uhn"},"outputs":[],"source":["data[0].shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"U8pYcWO16xqb"},"outputs":[],"source":["# converting image list and label list to numpy arrays\n","\n","X = np.array(data)\n","Y = np.array(labels)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nOJumzSg7JD4"},"outputs":[],"source":["type(X)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uSvCqSFv7J-7"},"outputs":[],"source":["type(Y)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CFcmRmnx7Ns2"},"outputs":[],"source":["print(X.shape)\n","print(Y.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LB1Rap2X7R98"},"outputs":[],"source":["print(Y)"]},{"cell_type":"markdown","metadata":{"id":"IZuq8fdc7e9x"},"source":["**Train Test Split**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"217vrhiO7c20"},"outputs":[],"source":["X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=2)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uCqTqdAB72zJ"},"outputs":[],"source":["print(X.shape, X_train.shape, X_test.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tQ8cYmhL76lZ"},"outputs":[],"source":["# scaling the data\n","\n","X_train_scaled = X_train/255\n","\n","X_test_scaled = X_test/255"]},{"cell_type":"markdown","metadata":{"id":"GPaQ0dfT_HnR"},"source":["These lines of code are scaling the training and test data by dividing each pixel value by 255. This is a common practice in image processing to normalize the data and improve the performance of machine learning models."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yMjyiUVH8FeB"},"outputs":[],"source":["X_train[0]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"V0cVGoJU8pWv"},"outputs":[],"source":["X_train_scaled[0]"]},{"cell_type":"markdown","metadata":{"id":"L5I-8fUA80iS"},"source":["**Building a Convolutional Neural Networks (CNN)**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"P0NZPpoQ8tZm"},"outputs":[],"source":["import tensorflow as tf\n","from tensorflow import keras"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OA9eSj2_9EMl"},"outputs":[],"source":["num_of_classes = 2\n","\n","model = keras.Sequential()\n","\n","# First convolutional block\n","model.add(keras.layers.Conv2D(32, kernel_size=(3,3), activation='relu', input_shape=(128,128,3)))\n","model.add(keras.layers.MaxPooling2D(pool_size=(2,2)))\n","\n","\n","model.add(keras.layers.Conv2D(64, kernel_size=(3,3), activation='relu'))\n","model.add(keras.layers.MaxPooling2D(pool_size=(2,2)))\n","\n","model.add(keras.layers.Flatten())\n","\n","model.add(keras.layers.Dense(128, activation='relu'))\n","model.add(keras.layers.Dropout(0.5))\n","\n","model.add(keras.layers.Dense(64, activation='relu'))\n","model.add(keras.layers.Dropout(0.5))\n","\n","\n","model.add(keras.layers.Dense(num_of_classes, activation='sigmoid'))"]},{"cell_type":"markdown","metadata":{"id":"Tk2ahaRG_lod"},"source":["- num_of_classes: This variable specifies the number of classes that the model will predict. In this case, it is set to 2.\n","- model: This variable stores the Keras model object.\n","- keras.Sequential(): This creates a sequential model, where each layer is added sequentially.\n","- model.add(keras.layers.Conv2D(...)): This adds a convolutional layer to the model.\n","- 32: This specifies the number of filters in the convolutional layer.\n","- kernel_size=(3,3): This specifies the size of the filter used in the convolution.\n","- activation='relu': This specifies the activation function used in the convolutional layer.\n","- input_shape=(128,128,3): This specifies the shape of the input images.\n","- model.add(keras.layers.MaxPooling2D(...)): This adds a max pooling layer to the model.\n","- pool_size=(2,2): This specifies the size of the pooling window.\n","- model.add(keras.layers.Flatten()): This flattens the output of the previous layer into a single dimension\n","- model.add(keras.layers.Dense(128, activation='relu')): This adds a dense layer with 128 units and ReLU activation.\n","- model.add(keras.layers.Dropout(0.5)): This adds a dropout layer with a rate of 0.5, which means that 50% of the units in the previous layer will be randomly dropped during training.\n","- model.add(keras.layers.Dense(64, activation='relu')): This adds another dense layer with 64 units and ReLU activation.\n","- model.add(keras.layers.Dropout(0.5)): This adds another dropout layer with a rate of 0.5.\n","- model.add(keras.layers.Dense(num_of_classes, activation='sigmoid')): This adds a final dense layer with a number of units equal to the number of classes and sigmoid activation."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8PS9_gb0_1F3"},"outputs":[],"source":["# compile the neural network\n","model.compile(optimizer='adam',\n","              loss='sparse_categorical_crossentropy',\n","              metrics=['acc'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gxbjDZaLAFdS"},"outputs":[],"source":["# training the neural network\n","history = model.fit(X_train_scaled, Y_train, validation_split=0.1, epochs=5)"]},{"cell_type":"markdown","metadata":{"id":"M7FVqeVIAyLK"},"source":["**Model Evaluation**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_IXu88q_AVo_"},"outputs":[],"source":["loss, accuracy = model.evaluate(X_test_scaled, Y_test)\n","print('Test Accuracy =', accuracy)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Qbk5iRtEA_xZ"},"outputs":[],"source":["h = history\n","\n","# plot the loss value\n","plt.plot(h.history['loss'], label='train loss')\n","plt.plot(h.history['val_loss'], label='validation loss')\n","plt.legend()\n","plt.show()\n","\n","# plot the accuracy value\n","plt.plot(h.history['acc'], label='train accuracy')\n","plt.plot(h.history['val_acc'], label='validation accuracy')\n","plt.legend()\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"uWvPB4q2ByT3"},"source":["**Predictive System**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lQNyqxFeBi3c"},"outputs":[],"source":["input_image_path = input('Path of the image to be predicted: ')\n","\n","input_image = cv2.imread(input_image_path)\n","\n","cv2_imshow(input_image)\n","\n","input_image_resized = cv2.resize(input_image, (128,128))\n","\n","input_image_scaled = input_image_resized/255\n","\n","input_image_reshaped = np.reshape(input_image_scaled, [1,128,128,3])\n","\n","input_prediction = model.predict(input_image_reshaped)\n","\n","print(input_prediction)\n","\n","\n","input_pred_label = np.argmax(input_prediction)\n","\n","print(input_pred_label)\n","\n","\n","if input_pred_label == 1:\n","\n","  print('The person in the image is wearing a mask')\n","\n","else:\n","\n","  print('The person in the image is not wearing a mask')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"x_Qw76_lDp0L"},"outputs":[],"source":["input_image_path = input('Path of the image to be predicted: ')\n","\n","input_image = cv2.imread(input_image_path)\n","\n","cv2_imshow(input_image)\n","\n","input_image_resized = cv2.resize(input_image, (128,128))\n","\n","input_image_scaled = input_image_resized/255\n","\n","input_image_reshaped = np.reshape(input_image_scaled, [1,128,128,3])\n","\n","input_prediction = model.predict(input_image_reshaped)\n","\n","print(input_prediction)\n","\n","\n","input_pred_label = np.argmax(input_prediction)\n","\n","print(input_pred_label)\n","\n","\n","if input_pred_label == 1:\n","\n","  print('The person in the image is wearing a mask')\n","\n","else:\n","\n","  print('The person in the image is not wearing a mask')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vWQO5TthD7mT"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}